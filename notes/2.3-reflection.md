# Reflection

## 1. What’s the cost per call (tokens × price)?

Cost depends on the model and the number of input/output tokens.

- **Summarization (`gpt-4o-mini`):**
  - Input: ~$0.15 / 1M tokens
  - Output: ~$0.60 / 1M tokens
- **Embeddings (`text-embedding-3-small`):**
  - ~$0.02 / 1M tokens

A typical 1,000-token note summarization might cost a fraction of a cent. The `usage` object returned by the API provides the exact token counts for each call.

## 2. How could you cache results locally?

The project already implements a robust local caching strategy for embeddings to reduce costs and latency.

- **Embeddings Cache:**
  - An in-memory cache (`Map`) provides the fastest lookups for repeated requests within the same session.
  - A disk cache (`cache/embeddings.json`) persists embeddings across server restarts. Text content is hashed (`sha1`) to create a stable cache key.
  - The cache is automatically loaded on the first request and saved to disk with a debounce mechanism to avoid excessive writes.

- **Summary Caching:**
  - While not currently implemented, summaries could be cached using a similar file-based approach. A hash of the note content could serve as the cache key.

## 3. How would you secure this if it were public?

If this app were exposed on the public internet, security must be layered across configuration, transport, application, data, and operations:

- API keys and secrets
  - Never expose the OpenAI key to the browser. Only the server should call OpenAI.
  - Require a per-request API key header (already supported via `X-API-Key`) and rotate keys regularly.
  - Store secrets in a managed secret store (e.g., AWS Secrets Manager, GCP Secret Manager) rather than plain env vars when possible.

- Authentication and authorization
  - Add user auth (OAuth/OIDC or email/password) with JWT sessions.
  - Enforce per-user roles (RBAC) and quotas (daily rate/credit caps) to prevent abuse.
  - Maintain an audit trail of requests (user, IP, model, size, status) for incident response.

- Network and transport
  - Enforce HTTPS everywhere; add HSTS and TLS modern ciphers.
  - Restrict CORS to trusted origins only; block `*`.
  - Put the API behind a WAF/CDN (Cloudflare/FASTLY) for DDoS protection and basic bot filtering.

- Input validation and abuse prevention
  - Validate and bound all inputs (length, type) with explicit limits (e.g., base64 max size, `maxTokens`, temperature ranges).
  - Keep JSON body limits reasonable and per-route (e.g., smaller for text chat; larger for audio/image endpoints).
  - Prefer presigned uploads or multipart uploads to object storage for very large files; avoid huge base64 JSON bodies when possible.
  - Implement rate limits (already present), IP-based throttling, and, when appropriate, CAPTCHA on unauthenticated endpoints.

- Data handling and privacy
  - Avoid storing PII; when necessary, encrypt at rest and in transit.
  - Store only metadata for large binaries (already done). If storing files, use storage with lifecycle rules and malware scanning.
  - Apply least-privilege Firestore/DB rules and segregate data by user.

- Headers and hardening
  - Use security headers (CSP, X-Content-Type-Options, Referrer-Policy) and disable `x-powered-by`.
  - Use `helmet` in Express for sensible defaults; set secure, HttpOnly, SameSite cookies.
  - Set timeouts on all external calls and clamp concurrency.

- Operations and monitoring
  - Add structured logs, metrics, and alerts on error spikes, rate-limit hits, and provider failures.
  - Automate dependency updates and vulnerability scanning (Snyk/GitHub Dependabot). Run SAST/DAST for code and app.
  - Separate environments (dev/stage/prod) and enforce infrastructure as code with reproducible provisioning.

## 4. What happens if OpenAI API is down?

Design for graceful degradation and quick recovery:

- Timeouts, retries, and circuit breakers
  - Set short timeouts for API calls (e.g., 10–20s) and apply exponential backoff retries for transient failures.
  - Use a circuit breaker to stop hammering a failing provider and return fast failures with helpful messages.

- User experience and messaging
  - Surface clear UI errors ("Service temporarily unavailable") and suggest trying again later.
  - Where possible, allow users to save prompts/tasks to a queue for deferred processing.

- Caching and stale-while-revalidate
  - Serve recently cached results for read-like operations (e.g., showing prior histories or summaries) when the provider is unavailable.

- Multi-provider or local fallbacks
  - Abstract the model provider behind an adapter interface so you can swap providers (e.g., OpenRouter, Together, Azure OpenAI) or reduce model quality temporarily.
  - For STT/TTS, consider local or alternative engines (e.g., Whisper local, Coqui TTS) for minimal functionality.

- Operations readiness
  - Health checks for provider dependencies; raise alerts on elevated error rates/latency.
  - Feature flags to disable affected features quickly without redeploying.
  - Post-incident, automatically drain deferred queues when the provider recovers and notify users of completion.
